# ROV_code
## 一、换机编译步骤
#### 1.删除Build目录
#### 2.执行catkin_make进行编译
#### 3.执行source devel/setup.bash，否则ros会找不到包
### 若是新配置的ubuntu系统，可在终端执行以下命令对环境一键配置：
sudo apt update
sudo apt install -y \
  ros-noetic-desktop-full \           # ROS Noetic 全量安装（含rviz、roscore、常用工具等）
  ros-noetic-mavros \                 # MAVROS 主包
  ros-noetic-mavros-extras \         # MAVROS 附加插件
  ros-noetic-serial \                # ROS 串口通信包
  ros-noetic-geographic-msgs \       # MAVROS 所需消息定义
  geographiclib-tools \              # 地理坐标库工具
  libserial-dev \                    # 系统级 C++ 串口库（非 ROS 专用）
  build-essential \                  # g++, make 等开发工具
  cmake \                            # 构建系统
  git \                              # Git 版本控制
  code \                             # Visual Studio Code 编辑器（需先配置微软源）
  python3-rosdep \                   # rosdep 依赖管理
  python3-rosinstall \               # ROS workspace 安装工具
  python3-rosinstall-generator \
  python3-wstool \
  python3-catkin-tools


## 二、总体架构
### 1.启动初始化功能包：rov_start_pkg
    这个包的作用是检查各个硬件与机载电脑的连接情况，由rov_init_node作为中控，向主题init_check不断发送自检请求，再订阅init_check_re获取各个节点的自检情况。最终的自检情况将被存储在一个map中，即rov_start_node.h的status_map中
#### （1）舵机自检
    根据总线舵机通信协议编写，使用串口向总线舵机发送ping命令，随后接收返回消息，观察其连接情况。若连接成功，则status_map["servo"]将会变为true
#### （2）双目摄像头自检
    因为使用的是UVC免驱动双目摄像头，故直接使用OpenCV尝试获取一帧图像，若获取成功，则status_map["camera"]将会变为true
### 2.头文件功能包
    这个包里面只有一个headfile.h，里面包含了要使用的库的头文件，要使用的时候直接调用#include"headfile_pkg/headfile.h"即可
    如果有要新增的库和头文件，建议直接在这里面进行添加或修改
### 3.控制功能包
    这个包作为本控制系统的核心功能包，计划实现：
    （1）对舵机的控制：包括自动化的变结构转换、手动调整各个舵机角度、监测每个舵机角度信息。【代码已完成，硬件未调试】后续规划：目标追踪过程中单目相机的角度控制也要使用舵机
    （2）电机控制：控制八个推进器的速度，这也是整个机体的核心控制策略，使用PID，但是目前还不知道硬件驱动方式，暂时没写
    （3）运动控制：目标追踪过程中的各个推进器的动力分配，机器人姿态的控制，也是核心控制策略
    （4）功能模块的动作控制：夹爪、网袋引导等
### 4.视觉包
    这个包包括一个双目摄像头和单目摄像头的控制代码，单目负责收集高清图像，主要作强化图像和目标识别。双目摄像头主要用于测距和定位，由于分辨率的限制，当前想到的思路是从单目的高清像素中映射到双目中，通过一个范围的限定后再在双目视野中进行定位，能提高效率和准确度【前提是单目摄像头的视角得跟双目相近】
    【以下是视觉实现的大体思路】
    （1）img_enhance_node:获取单目视觉的图像，存储Mat变量并调用强化算法API进行增强，输出处理后的Mat变量。同时调用AI模型进行识别，输出识别结果：类型、像素坐标
    （2）trace_locate_node:通过双目摄像头测距和定位，利用单目视觉的模糊识别区域二次识别，进行精准定位，引导控制包使机体变换至合适位置
    （3）enable_cal_node:做一些具体的任务，比如某一些产物的统计、工作海域巡逻以及阶段比对等
### 5.传感器和全局定位包
    按照我对飞控的理解，飞控好像是自带GPS的，利用飞控的GPS对机器人做个定位防丢失。各个传感器用于测量水文数据，包括深度、水温等等，总之服务于海洋牧场的相关需求
    【以下是大体思路】
    （1）location_node:对机器人进行GPS定位，防止丢失
    （2）route_plan_node:设定机器人工作半径和自动工作的范围，规划路径和续航
    （3）sensor_collect_node:获取各个传感器的数据，返回给功能模块等模块使用，这个包最好用头文件作外部变量
### 6.功能模块包
    这个包用于控制各个功能模块，每一个节点一个功能，把每一个功能都进行封装，做到即插即用
    【以下是大体思路】
    （1）夹爪部分
    （2）slam海底环境建图
    （3）拖网作业或其他近海水下作业模块
### 7.监测功能包
    这个包用于监测机器人各项关键数据，保障机器人运行安全，并用于系统复杂后的调试和维护
    （1）硬件检测节点：包括各个硬件连接情况，电池，机身温度，舱内湿度或漏水检测等
    （2）急停节点：故障使用，紧急断电，具体连接电池管理模块
    （3）重启调试节点：作脚本使用，重启整台机器人控制系统
### 8.其他构想
    可以做海面补给站，实现在工作半径内无限工作无限续航，专门分配一个包用来作充电模式用。补给站用海洋浮漂+太阳能板那样……
